{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU1M2RolandoL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2t5zPQ6vkXI"
      },
      "source": [
        "En este proyecto la idea es hacer un programa que sepa identificar un mensaje spam escrito en español.\r\n",
        "Al no conseguir un dataset con mensajes en español para poder entrenar,\r\n",
        "decidi traducir el mensaje a analizar y usar un dataset en ingles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaAQcH0HuZvk"
      },
      "source": [
        "import csv\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA3vdLjIvFCE"
      },
      "source": [
        "![ ! -f spam.csv ] && wget https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIq9oMGBqeAp"
      },
      "source": [
        "dfspam = pd.read_csv(\"spam.csv\", encoding='latin-1')[[\"v1\",\"v2\"]]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iESXwCGBDr0Z"
      },
      "source": [
        "import string\r\n",
        "punctuation = set(string.punctuation)\r\n",
        "\r\n",
        "#Funcion tokenize, elimina los caracteres de puntuacion, \r\n",
        "#pone en minuscula todas las letras y divide las oraciones en palabras\r\n",
        "#y a su vez cada oracion en vectores\r\n",
        "\r\n",
        "def tokenize(sentence):\r\n",
        "    tokens = []\r\n",
        "    for token in sentence.split():\r\n",
        "        new_token = []\r\n",
        "        for character in token:\r\n",
        "            if character not in punctuation:\r\n",
        "                new_token.append(character.lower())\r\n",
        "        if new_token:\r\n",
        "            tokens.append(\"\".join(new_token))\r\n",
        "    return tokens"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjJx71vlQB06",
        "outputId": "abaeef2f-9805-4f45-894a-141c790b9b28"
      },
      "source": [
        "#Probando tokenize\r\n",
        "dfspam.head()[\"v2\"].apply(tokenize)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [go, until, jurong, point, crazy, available, o...\n",
              "1                       [ok, lar, joking, wif, u, oni]\n",
              "2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
              "4    [nah, i, dont, think, he, goes, to, usf, he, l...\n",
              "Name: v2, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysP0_3_-CRM5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "#Division de mensajes y etiquetas para entrenamiento y para prueba\r\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(dfspam[\"v2\"], dfspam[\"v1\"], stratify=dfspam[\"v1\"])"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLjCptLDCRWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7006da-6a26-432a-965e-da9cd103cb47"
      },
      "source": [
        "#Creacion de matriz para acondicionar los datos \r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "Vectorizer = CountVectorizer(tokenizer = tokenize, binary=True)\r\n",
        "\r\n",
        "train_X = Vectorizer.fit_transform(train_text)\r\n",
        "test_X = Vectorizer.transform(test_text)\r\n",
        "\r\n",
        "train_X.shape"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4179, 8151)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptmhb4jpWPCW",
        "outputId": "868dc794-6132-4e20-9faa-281938b86a3b"
      },
      "source": [
        "#Libreria para la clasificacion de los mensajes\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "#Se entrena con los datos\r\n",
        "classifier = LinearSVC()\r\n",
        "classifier.fit(train_X, train_labels)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXiM0_JCczdh"
      },
      "source": [
        "import requests\r\n",
        "\r\n",
        "#Esta funcion para traducir la encontre en un foro, no necesita instalar liberias por eso la uso. Puede fallar a veces\r\n",
        "def Traduccion(source, target, text):\r\n",
        "    parametros = {'sl': source, 'tl': target, 'q': text}\r\n",
        "    cabeceras = {\"Charset\":\"UTF-8\",\"User-Agent\":\"AndroidTranslate/5.3.0.RC02.130475354-53000263 5.1 phone TRANSLATE_OPM5_TEST_1\"}\r\n",
        "    url = \"https://translate.google.com/translate_a/single?client=at&dt=t&dt=ld&dt=qca&dt=rm&dt=bd&dj=1&hl=es-ES&ie=UTF-8&oe=UTF-8&inputm=2&otf=2&iid=1dd3b944-fa62-4b55-b330-74909a99969e\"\r\n",
        "    response = requests.post(url, data=parametros, headers=cabeceras)\r\n",
        "    if response.status_code == 200:\r\n",
        "        for x in response.json()['sentences']:\r\n",
        "            return x['trans']\r\n",
        "    else:\r\n",
        "        return \"Ocurrió un error\"\r\n"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hX1rkXKXbsQ"
      },
      "source": [
        "#Determinamos el o los mensajes a clasificar \r\n",
        "mensaje1 = \"Ha Ganado, por favor envie un mensaje al 8899\"\r\n",
        "mensaje2 = \"Hola, como estas?\"\r\n",
        "mensaje3 = \"Como estas Mariana espero verte esta noche\"\r\n",
        "mensaje4 = \"Has ganado una entrada GRATIS, para ver a los Rolling Stone\"\r\n",
        "mensaje5 = \"a las 4 voy a la quinta, te espero\"\r\n",
        "\r\n",
        "ejemplos = [\r\n",
        "            mensaje1,\r\n",
        "            mensaje2,\r\n",
        "            mensaje3,\r\n",
        "            mensaje4,\r\n",
        "            mensaje5\r\n",
        "]\r\n",
        "\r\n",
        "examples = [\r\n",
        "    mje1,\r\n",
        "    mje2,\r\n",
        "    mje3,\r\n",
        "    mje4,\r\n",
        "    mje5\r\n",
        "]\r\n",
        "\r\n",
        "for ej, ex in zip(ejemplos, examples):\r\n",
        "  ex = Traduccion(\"es\", \"en\", ej)\r\n",
        "\r\n",
        "#Tokenizamos los mensajes para poder despues pasarlo a la funcion y asi clasificarlos\r\n",
        "examples_X = Vectorizer.transform(examples)\r\n",
        "predicciones = classifier.predict(examples_X)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npPl9Hz2XeuO",
        "outputId": "3c2d8493-57ae-4c8e-cb3c-fd9796305e6a"
      },
      "source": [
        "for text, label in zip(ejemplos, predicciones):\r\n",
        "    print(f\"{label:5} - {text}\")"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spam  - Ha Ganado, por favor envie un mensaje al 8899\n",
            "ham   - Hola, como estas?\n",
            "ham   - Como estas Mariana espero verte esta noche\n",
            "spam  - Has ganado una entrada GRATIS, para ver a los Rolling Stone\n",
            "ham   - a las 4 voy a la quinta, te espero\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}